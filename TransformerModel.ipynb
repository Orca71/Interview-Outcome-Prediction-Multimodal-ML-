{"cells":[{"cell_type":"code","execution_count":null,"id":"c21aa3ef-67fc-45f5-a9e6-a512f89a574b","metadata":{"id":"c21aa3ef-67fc-45f5-a9e6-a512f89a574b"},"outputs":[],"source":["!pip install --upgrade --quiet openai"]},{"cell_type":"code","execution_count":null,"id":"c448a7ab-f3eb-457a-9c8c-17cc5f02876b","metadata":{"id":"c448a7ab-f3eb-457a-9c8c-17cc5f02876b"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from scipy.stats import pearsonr\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","#BERT:\n","import torch\n","from transformers import BertTokenizer, BertModel\n","from tqdm import tqdm\n","#Random forest:\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","#FFN\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.preprocessing import StandardScaler\n","#Multimodal ML\n","import re\n","from sklearn.feature_selection import SelectKBest, f_regression\n","#Explainable ML\n","from lime.lime_tabular import LimeTabularExplainer"]},{"cell_type":"code","execution_count":null,"id":"cd88cfe1-acd6-412a-94fa-4082234ed9d4","metadata":{"id":"cd88cfe1-acd6-412a-94fa-4082234ed9d4"},"outputs":[],"source":["trancripts_csv = pd.read_csv(\"transcripts.csv\", header=None, names=[\"Participant\", \"Transcripts\"])\n","scores_csv = pd.read_csv(\"scores.csv\")"]},{"cell_type":"code","execution_count":null,"id":"ab18f9b9-7218-4824-9274-a7050f82a90e","metadata":{"id":"ab18f9b9-7218-4824-9274-a7050f82a90e"},"outputs":[],"source":["import pandas as pd\n","import re, string, nltk\n","from nltk import word_tokenize\n","nltk.download('punkt', quiet=True)\n","\n","df_merge = pd.merge(trancripts_csv, scores_csv, on=\"Participant\", how='inner')\n","\n","# Minimal text‑cleaning function --------------------------------------------\n","def clean(text: str) -> str:\n","    text = text.lower()\n","    text = re.sub(r\"\\d+\", \" \", text)           # remove digits\n","    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n","    text = re.sub(r\"\\s{2,}\", \" \", text)        # squeeze spaces\n","    return text.strip()\n","\n","df_merge[\"Transcripts\"] = df_merge[\"Transcripts\"].apply(clean)"]},{"cell_type":"code","execution_count":null,"id":"a77f0f73-a9de-4faf-b876-4e3022d8e284","metadata":{"id":"a77f0f73-a9de-4faf-b876-4e3022d8e284","outputId":"03c6e322-c39f-463c-fbc6-0b6989b3c24b"},"outputs":[{"name":"stdin","output_type":"stream","text":["Paste your OpenAI key:  ········\n"]}],"source":["import os, getpass\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your OpenAI key: \")\n","\n","from openai import OpenAI\n","client = OpenAI()"]},{"cell_type":"code","execution_count":null,"id":"68b653d0-67ea-4960-9c6d-f9becbe442d1","metadata":{"id":"68b653d0-67ea-4960-9c6d-f9becbe442d1","outputId":"8e7ca420-0ac7-43f4-b623-169fc6d40c96"},"outputs":[{"name":"stderr","output_type":"stream","text":["Fold 1/5: 100%|█████████████████████████████████| 28/28 [01:05<00:00,  2.33s/it]\n","Fold 2/5: 100%|█████████████████████████████████| 28/28 [01:02<00:00,  2.22s/it]\n","Fold 3/5: 100%|█████████████████████████████████| 28/28 [07:25<00:00, 15.92s/it]\n","Fold 4/5: 100%|█████████████████████████████████| 27/27 [01:07<00:00,  2.50s/it]\n","Fold 5/5: 100%|█████████████████████████████████| 27/27 [01:00<00:00,  2.25s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Collected 138 / 138 predictions\n","GPT‑4o‑mini results (5‑fold):\n","  Overall   r = 0.484   RE = 0.070\n","  Excitement r = 0.353   RE = 0.104\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import os, re, json, random, time\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from scipy.stats import pearsonr\n","from sklearn.model_selection import GroupKFold\n","from openai import OpenAI\n","\n","# ------------------------------------------------------------\n","# 2.1  Load your dataframe (⇐ already in memory for you)\n","# ------------------------------------------------------------\n","df = df_merge.copy()            # columns: Participant, Transcripts, Overall, Excited\n","groups = df[\"Participant\"]\n","\n","# ------------------------------------------------------------\n","# 2.2  OpenAI client\n","# ------------------------------------------------------------\n","client = OpenAI()               # reads OPENAI_API_KEY from env\n","MODEL = \"gpt-4.1-mini\"           # or \"gpt-4.1-mini\" if enabled for your org\n","\n","# ------------------------------------------------------------\n","# 2.3  Prompt template\n","# ------------------------------------------------------------\n","TEMPLATE = \"\"\"You are an HR expert.\\nGiven an interview transcript, rate:\\n• overall performance (1–7)\\n• excitement/enthusiasm (1–7)\\nReturn strict JSON: {{\\\"overall\\\": <float>, \\\"excitement\\\": <float>, \\\"explanation\\\": \\\"<why>\\\"}}\\n{fewshot}\\n<TRANSCRIPT>\\n{transcript}\\n</TRANSCRIPT>\\nJSON:\n","\"\"\"\n","\n","def make_fewshot(df_sub, n=2):\n","    \"\"\"Pick n random labelled examples to include in the prompt.\"\"\"\n","    rows = random.sample(list(df_sub.index), n)\n","    shots = []\n","    for idx in rows:\n","        row = df_sub.loc[idx]\n","        shots.append(\n","f\"\"\"Example:\n","<TRANSCRIPT>\n","{row['Transcripts'][:600]}\n","</TRANSCRIPT>\n","{{\"overall\": {row['Overall']:.1f}, \"excitement\": {row['Excited']:.1f}, \"explanation\": \"sample\"}}\"\"\"\n","        )\n","    return \"\\n\".join(shots)\n","\n","# ------------------------------------------------------------\n","# 2.4  Single‑call helper\n","# ------------------------------------------------------------\n","def gpt_score(prompt):\n","    \"\"\"Returns (overall, excitement, explanation) or None.\"\"\"\n","    try:\n","        rsp = client.chat.completions.create(\n","            model=MODEL,\n","            messages=[{\"role\": \"user\", \"content\": prompt}],\n","            temperature=0.2,\n","            max_tokens=120,\n","            response_format={\"type\": \"json_object\"}   # forces JSON output\n","        )\n","        js = json.loads(rsp.choices[0].message.content)\n","        return float(js[\"overall\"]), float(js[\"excitement\"]), js[\"explanation\"]\n","    except Exception as e:\n","        print(\"⚠️  GPT call failed:\", e)\n","        return None\n","\n","# ------------------------------------------------------------\n","# 2.5  5‑fold participant‑level CV\n","# ------------------------------------------------------------\n","fold = GroupKFold(n_splits=5)\n","records = []\n","\n","for f, (tr, te) in enumerate(fold.split(df, groups=groups)):\n","    fewshot = make_fewshot(df.iloc[tr], n=2)\n","\n","    for idx in tqdm(te, desc=f\"Fold {f+1}/5\"):\n","        txt = df.at[idx, \"Transcripts\"][:1800]      # keep cost low\n","        prompt = TEMPLATE.format(fewshot=fewshot, transcript=txt)\n","        res = gpt_score(prompt)\n","        if res is None:\n","            continue\n","        o_hat, e_hat, expl = res\n","        records.append({\n","            \"idx\": idx, \"fold\": f,\n","            \"o_hat\": o_hat, \"e_hat\": e_hat,\n","            \"o_true\": df.at[idx, \"Overall\"],\n","            \"e_true\": df.at[idx, \"Excited\"],\n","            \"explanation\": expl\n","        })\n","        time.sleep(0.5)   # polite rate‑limit; tweak as needed\n","\n","out = pd.DataFrame(records)\n","print(f\"\\nCollected {len(out)} / {len(df)} predictions\")\n","\n","# ------------------------------------------------------------\n","# 2.6  Metrics\n","# ------------------------------------------------------------\n","def rel_err(y, yhat, max_score=7):\n","    return np.mean(np.abs(yhat - y)) / max_score\n","\n","r_overall = pearsonr(out[\"o_true\"], out[\"o_hat\"])[0]\n","re_overall = rel_err(out[\"o_true\"], out[\"o_hat\"])\n","r_excited = pearsonr(out[\"e_true\"], out[\"e_hat\"])[0]\n","re_excited = rel_err(out[\"e_true\"], out[\"e_hat\"])\n","\n","print(f\"GPT‑4.1‑mini results (5‑fold):\")\n","print(f\"  Overall   r = {r_overall:.3f}   RE = {re_overall:.3f}\")\n","print(f\"  Excitement r = {r_excited:.3f}   RE = {re_excited:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"ff2a25d0-988d-48bc-b067-b6e5a2be43cc","metadata":{"id":"ff2a25d0-988d-48bc-b067-b6e5a2be43cc","outputId":"e31f26a8-3677-4c05-c72f-ce6a42abafcd"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["records"]},{"cell_type":"code","execution_count":null,"id":"e745ac13-afbd-4618-ae5b-9790c402924e","metadata":{"id":"e745ac13-afbd-4618-ae5b-9790c402924e"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}